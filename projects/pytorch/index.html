<!doctype html><html lang=en dir=ltr class=scroll-smooth data-default-appearance=dark data-auto-appearance=true><head><meta charset=utf-8><meta http-equiv=content-language content="en"><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="ie=edge"><title>pytorch &#183; Jake Roggenbuck</title><meta name=title content="pytorch &#183; Jake Roggenbuck"><meta name=description content="Tensors and Dynamic neural networks in Python with strong GPU acceleration"><meta name=keywords content="Python,"><link rel=canonical href=/projects/pytorch/><link type=text/css rel=stylesheet href=/css/main.bundle.min.4d4b1b35ed4fb37d198f5f4fa732e64404b535101cdef4401ac22e7c91380b82f3c8e5d51ae61f0149e6a95694c77e5a40943ca8480609a230c10f33c1fc11b4.css integrity="sha512-TUsbNe1Ps30Zj19PpzLmRAS1NRAc3vRAGsIufJE4C4LzyOXVGuYfAUnmqVaUx35aQJQ8qEgGCaIwwQ8zwfwRtA=="><script type=text/javascript src=/js/appearance.min.516a16745bea5a9bd011138d254cc0fd3973cd55ce6e15f3dec763e7c7c2c7448f8fe7b54cca811cb821b0c7e12cd161caace1dd794ac3d34d40937cbcc9ee12.js integrity="sha512-UWoWdFvqWpvQERONJUzA/TlzzVXObhXz3sdj58fCx0SPj+e1TMqBHLghsMfhLNFhyqzh3XlKw9NNQJN8vMnuEg=="></script>
<script defer type=text/javascript id=script-bundle src=/js/main.bundle.min.006a5ac4ddc20468d3cbac5f715178db0c4e87ec9673e6f6bc123ea9d5b9368c9c5323358b3f6eb419028d87c3c45a8d704eedbee9458cc2d0596554a058d611.js integrity="sha512-AGpaxN3CBGjTy6xfcVF42wxOh+yWc+b2vBI+qdW5NoycUyM1iz9utBkCjYfDxFqNcE7tvulFjMLQWWVUoFjWEQ==" data-copy data-copied></script>
<script src=/js/zoom.min.js></script>
<link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/site.webmanifest><meta property="og:title" content="pytorch"><meta property="og:description" content="Tensors and Dynamic neural networks in Python with strong GPU acceleration"><meta property="og:type" content="article"><meta property="og:url" content="/projects/pytorch/"><meta property="article:section" content="projects"><meta property="article:published_time" content="2024-08-29T00:00:00+00:00"><meta property="article:modified_time" content="2024-08-29T00:00:00+00:00"><meta property="og:site_name" content="Jake Roggenbuck"><meta name=twitter:card content="summary"><meta name=twitter:title content="pytorch"><meta name=twitter:description content="Tensors and Dynamic neural networks in Python with strong GPU acceleration"><script type=application/ld+json>[{"@context":"https://schema.org","@type":"Article","articleSection":"Projects","name":"pytorch","headline":"pytorch","description":"Tensors and Dynamic neural networks in Python with strong GPU acceleration","abstract":"PyTorch is a Python package that provides two high-level features:","inLanguage":"en","url":"\/projects\/pytorch\/","author":{"@type":"Person","name":"Jake Roggenbuck"},"copyrightYear":"2024","dateCreated":"2024-08-29T00:00:00\u002b00:00","datePublished":"2024-08-29T00:00:00\u002b00:00","dateModified":"2024-08-29T00:00:00\u002b00:00","keywords":["Python"],"mainEntityOfPage":"true","wordCount":"2811"}]</script><meta name=author content="Jake Roggenbuck"><link href=mailto:me@jr0.org rel=me><link href=https://github.com/jakeroggenbuck rel=me><link href=https://linkedin.com/in/jakeroggenbuck rel=me><script src=/lib/jquery/jquery.slim.min.js integrity></script><meta name=theme-color><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.css integrity=sha384-Xi8rHCmBmhbuyyhbI88391ZKP2dmfnOl4rT9ZfRI7mLTdk1wblIUnrIq35nqwEvC crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.js integrity=sha384-X/XCfMm41VSsqRNQgDerQczD69XqmjOOOwYQvr/uuC+j4OPoNhVgjdGFwhvN02Ja crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous></script>
<script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],throwOnError:!1})})</script><script>!function(e,t){var n,s,o,i;t.__SV||(window.posthog=t,t._i=[],t.init=function(a,r,c){function d(e,t){var n=t.split(".");2==n.length&&(e=e[n[0]],t=n[1]),e[t]=function(){e.push([t].concat(Array.prototype.slice.call(arguments,0)))}}(s=e.createElement("script")).type="text/javascript",s.async=!0,s.src=r.api_host+"/static/array.js",(i=e.getElementsByTagName("script")[0]).parentNode.insertBefore(s,i);var l=t;for(void 0!==c?l=t[c]=[]:c="posthog",l.people=l.people||[],l.toString=function(e){var t="posthog";return"posthog"!==c&&(t+="."+c),e||(t+=" (stub)"),t},l.people.toString=function(){return l.toString(1)+".people (stub)"},o="capture identify alias people.set people.set_once set_config register register_once unregister opt_out_capturing has_opted_out_capturing opt_in_capturing reset isFeatureEnabled onFeatureFlags".split(" "),n=0;n<o.length;n++)d(l,o[n]);t._i.push([a,r,c])},t.__SV=1)}(document,window.posthog||[]),posthog.init("phc_ML7OV6jGM1EXu0tXlV5CUqJgBSduSsgx8U2HaLEiIX",{api_host:"https://app.posthog.com"})</script></head><body class="flex flex-col h-screen px-6 m-auto text-lg leading-7 max-w-7xl bg-neutral text-neutral-900 dark:bg-neutral-800 dark:text-neutral sm:px-14 md:px-24 lg:px-32"><div id=the-top class="absolute flex self-center"><a class="px-3 py-1 text-sm -translate-y-8 rounded-b-lg bg-primary-200 focus:translate-y-0 dark:bg-neutral-600" href=#main-content><span class="font-bold text-primary-600 ltr:pr-2 rtl:pl-2 dark:text-primary-400">&darr;</span>Skip to main content</a></div><div style=padding-left:0;padding-right:0;padding-top:2px;padding-bottom:3px class="main-menu flex items-center justify-between px-4 py-6 sm:px-6 md:justify-start space-x-3"><div class="flex flex-1 items-center justify-between"><nav class="flex space-x-3"><a href=/ class="text-base font-medium text-gray-500 hover:text-gray-900">Jake Roggenbuck</a></nav><nav class="hidden md:flex items-center space-x-5 md:ml-12 h-12"><a href=/projects/ class="flex items-center"><p class="text-base font-medium text-gray-500 hover:text-gray-900" title=Projects>Projects</p></a><a href=/posts/ class="flex items-center"><p class="text-base font-medium text-gray-500 hover:text-gray-900" title=Posts>Blog</p></a><a href=/archive/ class="flex items-center"><p class="text-base font-medium text-gray-500 hover:text-gray-900" title=Archive>Archive</p></a><button id=search-button aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400 h-12" title>
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></button><div class="ltr:mr-14 rtl:ml-14 cursor-pointer text-sm text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400"><button id=appearance-switcher aria-label="Dark mode switcher" type=button><div class="flex items-center justify-center h-12 dark:hidden"><span class="relative block icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentcolor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden h-12 dark:flex"><span class="relative block icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentcolor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></nav><div class="flex md:hidden items-center space-x-5 md:ml-12"><span></span>
<button id=search-button-mobile aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title>
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></button>
<button id=appearance-switcher-mobile aria-label="Dark mode switcher" type=button style=margin-right:5px><div class="flex items-center justify-center h-12 dark:hidden"><span class="relative block icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentcolor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden h-12 dark:flex"><span class="relative block icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentcolor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></div><div class="-my-2 -mr-2 md:hidden"><label id=menu-button for=menu-controller class=block><input type=checkbox id=menu-controller class=hidden><div class="cursor-pointer hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentcolor" d="M0 96C0 78.33 14.33 64 32 64H416c17.7.0 32 14.33 32 32 0 17.7-14.3 32-32 32H32C14.33 128 0 113.7.0 96zM0 256c0-17.7 14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32H32c-17.67.0-32-14.3-32-32zM416 448H32c-17.67.0-32-14.3-32-32s14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32z"/></svg></span></div><div id=menu-wrapper style=padding-top:5px class="fixed inset-0 z-30 invisible w-screen h-screen m-0 overflow-auto transition-opacity opacity-0 cursor-default bg-neutral-100/50 backdrop-blur-sm dark:bg-neutral-900/50"><ul class="flex space-y-2 mt-3 flex-col items-end w-full px-6 py-6 mx-auto overflow-visible list-none ltr:text-right rtl:text-left max-w-7xl"><li><span class="cursor-pointer inline-block align-text-bottom hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></span></li><li class=mt-1><a href=/projects/ class="flex items-center"><p class="text-bg font-bg text-gray-500 hover:text-gray-900" title=Projects>Projects</p></a></li><li class=mt-1><a href=/posts/ class="flex items-center"><p class="text-bg font-bg text-gray-500 hover:text-gray-900" title=Posts>Blog</p></a></li><li class=mt-1><a href=/archive/ class="flex items-center"><p class="text-bg font-bg text-gray-500 hover:text-gray-900" title=Archive>Archive</p></a></li></ul></div></label></div></div><div class="relative flex flex-col grow"><main id=main-content class=grow><article><header id=single_header class="mt-5 max-w-prose"><ol class="text-sm text-neutral-500 dark:text-neutral-400 print:hidden"><li class="inline hidden"><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/></a><span class="px-1 text-primary-500">/</span></li><li class=inline><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/projects/>Projects</a><span class="px-1 text-primary-500">/</span></li><li class="inline hidden"><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/projects/pytorch/>pytorch</a><span class="px-1 text-primary-500">/</span></li></ol><h1 class="mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">pytorch</h1><div class="mt-1 mb-6 text-base text-neutral-500 dark:text-neutral-400 print:hidden"><div class="flex flex-row flex-wrap items-center"><time datetime="2024-08-29 00:00:00 +0000 UTC">29 August 2024</time><span class="px-2 text-primary-500">&#183;</span><span>2811 words</span><span class="px-2 text-primary-500">&#183;</span><span title="Reading time">14 mins</span></div></div><div class=flex><img class="!mt-0 !mb-0 h-24 w-24 rounded-full ltr:mr-4 rtl:ml-4" width=96 height=96 alt="Jake Roggenbuck" src=/jake-profile-2_hu5c441416fff170c71d20e1ff858469cd_88398_192x192_fill_q75_box_center.jpg><div class=place-self-center><div class="text-[0.6rem] uppercase leading-3 text-neutral-500 dark:text-neutral-400">Author</div><div class="font-semibold leading-6 text-neutral-800 dark:text-neutral-300">Jake Roggenbuck</div><div class="text-sm text-neutral-700 dark:text-neutral-400">Working at Capital One as a SWE Intern as well as Programming Language Research during the school year.</div><div class="text-2xl sm:text-lg"><div class="flex flex-wrap text-neutral-400 dark:text-neutral-500"><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=mailto:me@jr0.org target=_blank aria-label=Email rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentcolor" d="M207.8 20.73c-93.45 18.32-168.7 93.66-187 187.1-27.64 140.9 68.65 266.2 199.1 285.1 19.01 2.888 36.17-12.26 36.17-31.49l1e-4-.6631c0-15.74-11.44-28.88-26.84-31.24-84.35-12.98-149.2-86.13-149.2-174.2.0-102.9 88.61-185.5 193.4-175.4 91.54 8.869 158.6 91.25 158.6 183.2v16.16c0 22.09-17.94 40.05-40 40.05s-40.01-17.96-40.01-40.05v-120.1c0-8.847-7.161-16.02-16.01-16.02l-31.98.0036c-7.299.0-13.2 4.992-15.12 11.68-24.85-12.15-54.24-16.38-86.06-5.106-38.75 13.73-68.12 48.91-73.72 89.64-9.483 69.01 43.81 128 110.9 128 26.44.0 50.43-9.544 69.59-24.88 24 31.3 65.23 48.69 109.4 37.49C465.2 369.3 496 324.1 495.1 277.2V256.3c0-149.2-133.9-265.632-287.3-235.57zM239.1 304.3c-26.47.0-48-21.56-48-48.05s21.53-48.05 48-48.05 48 21.56 48 48.05-20.6 48.05-48 48.05z"/></svg></span></span></a><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://github.com/jakeroggenbuck target=_blank aria-label=Github rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></span></a><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://linkedin.com/in/jakeroggenbuck target=_blank aria-label=Linkedin rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentcolor" d="M416 32H31.9C14.3 32 0 46.5.0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6.0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3.0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2.0 38.5 17.3 38.5 38.5.0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6.0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2.0 79.7 44.3 79.7 101.9V416z"/></svg></span></span></a></div></div></div></div><div class=mb-5></div></header><section class="flex flex-col max-w-full mt-0 prose dark:prose-invert lg:flex-row"><div class="min-w-0 min-h-0 max-w-fit"><div class="max-w-prose mb-20"><p><figure><img class="my-0 rounded-md" src=https://github.com/pytorch/pytorch/raw/main/docs/source/_static/img/pytorch-logo-dark.png alt="PyTorch Logo"></figure></p><hr><p>PyTorch is a Python package that provides two high-level features:</p><ul><li>Tensor computation (like NumPy) with strong GPU acceleration</li><li>Deep neural networks built on a tape-based autograd system</li></ul><p>You can reuse your favorite Python packages such as NumPy, SciPy, and Cython to extend PyTorch when needed.</p><p>Our trunk health (Continuous Integration signals) can be found at <a href=https://hud.pytorch.org/ci/pytorch/pytorch/main target=_blank>hud.pytorch.org</a>.</p><ul><li><a href=#more-about-pytorch>More About PyTorch</a><ul><li><a href=#a-gpu-ready-tensor-library>A GPU-Ready Tensor Library</a></li><li><a href=#dynamic-neural-networks-tape-based-autograd>Dynamic Neural Networks: Tape-Based Autograd</a></li><li><a href=#python-first>Python First</a></li><li><a href=#imperative-experiences>Imperative Experiences</a></li><li><a href=#fast-and-lean>Fast and Lean</a></li><li><a href=#extensions-without-pain>Extensions Without Pain</a></li></ul></li><li><a href=#installation>Installation</a><ul><li><a href=#binaries>Binaries</a><ul><li><a href=#nvidia-jetson-platforms>NVIDIA Jetson Platforms</a></li></ul></li><li><a href=#from-source>From Source</a><ul><li><a href=#prerequisites>Prerequisites</a><ul><li><a href=#nvidia-cuda-support>NVIDIA CUDA Support</a></li><li><a href=#amd-rocm-support>AMD ROCm Support</a></li><li><a href=#intel-gpu-support>Intel GPU Support</a></li></ul></li><li><a href=#get-the-pytorch-source>Get the PyTorch Source</a></li><li><a href=#install-dependencies>Install Dependencies</a></li><li><a href=#install-pytorch>Install PyTorch</a><ul><li><a href=#adjust-build-options-optional>Adjust Build Options (Optional)</a></li></ul></li></ul></li><li><a href=#docker-image>Docker Image</a><ul><li><a href=#using-pre-built-images>Using pre-built images</a></li><li><a href=#building-the-image-yourself>Building the image yourself</a></li></ul></li><li><a href=#building-the-documentation>Building the Documentation</a></li><li><a href=#previous-versions>Previous Versions</a></li></ul></li><li><a href=#getting-started>Getting Started</a></li><li><a href=#resources>Resources</a></li><li><a href=#communication>Communication</a></li><li><a href=#releases-and-contributing>Releases and Contributing</a></li><li><a href=#the-team>The Team</a></li><li><a href=#license>License</a></li></ul><div id=more-about-pytorch class=anchor></div><h2 class="relative group">More About PyTorch
<span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#more-about-pytorch aria-label=Anchor>#</a></span></h2><p><a href=https://pytorch.org/tutorials/beginner/basics/intro.html target=_blank>Learn the basics of PyTorch</a></p><p>At a granular level, PyTorch is a library that consists of the following components:</p><table><thead><tr><th>Component</th><th>Description</th></tr></thead><tbody><tr><td><a href=https://pytorch.org/docs/stable/torch.html target=_blank><strong>torch</strong></a></td><td>A Tensor library like NumPy, with strong GPU support</td></tr><tr><td><a href=https://pytorch.org/docs/stable/autograd.html target=_blank><strong>torch.autograd</strong></a></td><td>A tape-based automatic differentiation library that supports all differentiable Tensor operations in torch</td></tr><tr><td><a href=https://pytorch.org/docs/stable/jit.html target=_blank><strong>torch.jit</strong></a></td><td>A compilation stack (TorchScript) to create serializable and optimizable models from PyTorch code</td></tr><tr><td><a href=https://pytorch.org/docs/stable/nn.html target=_blank><strong>torch.nn</strong></a></td><td>A neural networks library deeply integrated with autograd designed for maximum flexibility</td></tr><tr><td><a href=https://pytorch.org/docs/stable/multiprocessing.html target=_blank><strong>torch.multiprocessing</strong></a></td><td>Python multiprocessing, but with magical memory sharing of torch Tensors across processes. Useful for data loading and Hogwild training</td></tr><tr><td><a href=https://pytorch.org/docs/stable/data.html target=_blank><strong>torch.utils</strong></a></td><td>DataLoader and other utility functions for convenience</td></tr></tbody></table><p>Usually, PyTorch is used either as:</p><ul><li>A replacement for NumPy to use the power of GPUs.</li><li>A deep learning research platform that provides maximum flexibility and speed.</li></ul><p>Elaborating Further:</p><div id=a-gpu-ready-tensor-library class=anchor></div><h3 class="relative group">A GPU-Ready Tensor Library
<span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#a-gpu-ready-tensor-library aria-label=Anchor>#</a></span></h3><p>If you use NumPy, then you have used Tensors (a.k.a. ndarray).</p><p><figure><img class="my-0 rounded-md" src=./docs/source/_static/img/tensor_illustration.png alt="Tensor illustration"></figure></p><p>PyTorch provides Tensors that can live either on the CPU or the GPU and accelerates the
computation by a huge amount.</p><p>We provide a wide variety of tensor routines to accelerate and fit your scientific computation needs
such as slicing, indexing, mathematical operations, linear algebra, reductions.
And they are fast!</p><div id=dynamic-neural-networks-tape-based-autograd class=anchor></div><h3 class="relative group">Dynamic Neural Networks: Tape-Based Autograd
<span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#dynamic-neural-networks-tape-based-autograd aria-label=Anchor>#</a></span></h3><p>PyTorch has a unique way of building neural networks: using and replaying a tape recorder.</p><p>Most frameworks such as TensorFlow, Theano, Caffe, and CNTK have a static view of the world.
One has to build a neural network and reuse the same structure again and again.
Changing the way the network behaves means that one has to start from scratch.</p><p>With PyTorch, we use a technique called reverse-mode auto-differentiation, which allows you to
change the way your network behaves arbitrarily with zero lag or overhead. Our inspiration comes
from several research papers on this topic, as well as current and past work such as
<a href=https://github.com/twitter/torch-autograd target=_blank>torch-autograd</a>,
<a href=https://github.com/HIPS/autograd target=_blank>autograd</a>,
<a href=https://chainer.org target=_blank>Chainer</a>, etc.</p><p>While this technique is not unique to PyTorch, it&rsquo;s one of the fastest implementations of it to date.
You get the best of speed and flexibility for your crazy research.</p><p><figure><img class="my-0 rounded-md" src=https://github.com/pytorch/pytorch/raw/main/docs/source/_static/img/dynamic_graph.gif alt="Dynamic graph"></figure></p><div id=python-first class=anchor></div><h3 class="relative group">Python First
<span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#python-first aria-label=Anchor>#</a></span></h3><p>PyTorch is not a Python binding into a monolithic C++ framework.
It is built to be deeply integrated into Python.
You can use it naturally like you would use <a href=https://www.numpy.org/ target=_blank>NumPy</a> / <a href=https://www.scipy.org/ target=_blank>SciPy</a> / <a href=https://scikit-learn.org target=_blank>scikit-learn</a> etc.
You can write your new neural network layers in Python itself, using your favorite libraries
and use packages such as <a href=https://cython.org/ target=_blank>Cython</a> and <a href=http://numba.pydata.org/ target=_blank>Numba</a>.
Our goal is to not reinvent the wheel where appropriate.</p><div id=imperative-experiences class=anchor></div><h3 class="relative group">Imperative Experiences
<span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#imperative-experiences aria-label=Anchor>#</a></span></h3><p>PyTorch is designed to be intuitive, linear in thought, and easy to use.
When you execute a line of code, it gets executed. There isn&rsquo;t an asynchronous view of the world.
When you drop into a debugger or receive error messages and stack traces, understanding them is straightforward.
The stack trace points to exactly where your code was defined.
We hope you never spend hours debugging your code because of bad stack traces or asynchronous and opaque execution engines.</p><div id=fast-and-lean class=anchor></div><h3 class="relative group">Fast and Lean
<span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#fast-and-lean aria-label=Anchor>#</a></span></h3><p>PyTorch has minimal framework overhead. We integrate acceleration libraries
such as <a href=https://software.intel.com/mkl target=_blank>Intel MKL</a> and NVIDIA (<a href=https://developer.nvidia.com/cudnn target=_blank>
cuDNN</a>, <a href=https://developer.nvidia.com/nccl target=_blank>NCCL</a>) to maximize speed.
At the core, its CPU and GPU Tensor and neural network backends
are mature and have been tested for years.</p><p>Hence, PyTorch is quite fast — whether you run small or large neural networks.</p><p>The memory usage in PyTorch is extremely efficient compared to Torch or some of the alternatives.
We&rsquo;ve written custom memory allocators for the GPU to make sure that
your deep learning models are maximally memory efficient.
This enables you to train bigger deep learning models than before.</p><div id=extensions-without-pain class=anchor></div><h3 class="relative group">Extensions Without Pain
<span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#extensions-without-pain aria-label=Anchor>#</a></span></h3><p>Writing new neural network modules, or interfacing with PyTorch&rsquo;s Tensor API was designed to be straightforward
and with minimal abstractions.</p><p>You can write new neural network layers in Python using the torch API
<a href=https://pytorch.org/tutorials/advanced/numpy_extensions_tutorial.html target=_blank>or your favorite NumPy-based libraries such as SciPy</a>.</p><p>If you want to write your layers in C/C++, we provide a convenient extension API that is efficient and with minimal boilerplate.
No wrapper code needs to be written. You can see <a href=https://pytorch.org/tutorials/advanced/cpp_extension.html target=_blank>a tutorial here</a> and <a href=https://github.com/pytorch/extension-cpp target=_blank>an example here</a>.</p><div id=installation class=anchor></div><h2 class="relative group">Installation
<span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#installation aria-label=Anchor>#</a></span></h2><div id=binaries class=anchor></div><h3 class="relative group">Binaries
<span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#binaries aria-label=Anchor>#</a></span></h3><p>Commands to install binaries via Conda or pip wheels are on our website: <a href=https://pytorch.org/get-started/locally/ target=_blank>https://pytorch.org/get-started/locally/</a></p><div id=nvidia-jetson-platforms class=anchor></div><h4 class="relative group">NVIDIA Jetson Platforms
<span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#nvidia-jetson-platforms aria-label=Anchor>#</a></span></h4><p>Python wheels for NVIDIA&rsquo;s Jetson Nano, Jetson TX1/TX2, Jetson Xavier NX/AGX, and Jetson AGX Orin are provided <a href=https://forums.developer.nvidia.com/t/pytorch-for-jetson-version-1-10-now-available/72048 target=_blank>here</a> and the L4T container is published <a href=https://catalog.ngc.nvidia.com/orgs/nvidia/containers/l4t-pytorch target=_blank>here</a></p><p>They require JetPack 4.2 and above, and <a href=https://github.com/dusty-nv target=_blank>@dusty-nv</a> and <a href=https://github.com/ptrblck target=_blank>@ptrblck</a> are maintaining them.</p><div id=from-source class=anchor></div><h3 class="relative group">From Source
<span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#from-source aria-label=Anchor>#</a></span></h3><div id=prerequisites class=anchor></div><h4 class="relative group">Prerequisites
<span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#prerequisites aria-label=Anchor>#</a></span></h4><p>If you are installing from source, you will need:</p><ul><li>Python 3.9 or later</li><li>A compiler that fully supports C++17, such as clang or gcc (gcc 9.4.0 or newer is required, on Linux)</li><li>Visual Studio or Visual Studio Build Tool (Windows only)</li></ul><p>* PyTorch CI uses Visual C++ BuildTools, which come with Visual Studio Enterprise,
Professional, or Community Editions. You can also install the build tools from
<a href=https://visualstudio.microsoft.com/visual-cpp-build-tools/ target=_blank>https://visualstudio.microsoft.com/visual-cpp-build-tools/</a>. The build tools <em>do not</em>
come with Visual Studio Code by default.</p><p>* We highly recommend installing an <a href=https://www.anaconda.com/download target=_blank>Anaconda</a> environment. You will get a high-quality BLAS library (MKL) and you get controlled dependency versions regardless of your Linux distro.</p><p>An example of environment setup is shown below:</p><ul><li>Linux:</li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>$ <span class=nb>source</span> &lt;CONDA_INSTALL_DIR&gt;/bin/activate
</span></span><span class=line><span class=cl>$ conda create -y -n &lt;CONDA_NAME&gt;
</span></span><span class=line><span class=cl>$ conda activate &lt;CONDA_NAME&gt;
</span></span></code></pre></div><ul><li>Windows:</li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>$ <span class=nb>source</span> &lt;CONDA_INSTALL_DIR&gt;<span class=se>\S</span>cripts<span class=se>\a</span>ctivate.bat
</span></span><span class=line><span class=cl>$ conda create -y -n &lt;CONDA_NAME&gt;
</span></span><span class=line><span class=cl>$ conda activate &lt;CONDA_NAME&gt;
</span></span><span class=line><span class=cl>$ call <span class=s2>&#34;C:\Program Files\Microsoft Visual Studio\&lt;VERSION&gt;\Community\VC\Auxiliary\Build\vcvarsall.bat&#34;</span> x64
</span></span></code></pre></div><div id=nvidia-cuda-support class=anchor></div><h5 class="relative group">NVIDIA CUDA Support
<span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#nvidia-cuda-support aria-label=Anchor>#</a></span></h5><p>If you want to compile with CUDA support, <a href=https://pytorch.org/get-started/locally/ target=_blank>select a supported version of CUDA from our support matrix</a>, then install the following:</p><ul><li><a href=https://developer.nvidia.com/cuda-downloads target=_blank>NVIDIA CUDA</a></li><li><a href=https://developer.nvidia.com/cudnn target=_blank>NVIDIA cuDNN</a> v8.5 or above</li><li><a href=https://gist.github.com/ax3l/9489132 target=_blank>Compiler</a> compatible with CUDA</li></ul><p>Note: You could refer to the <a href=https://docs.nvidia.com/deeplearning/cudnn/reference/support-matrix.html target=_blank>cuDNN Support Matrix</a> for cuDNN versions with the various supported CUDA, CUDA driver and NVIDIA hardware</p><p>If you want to disable CUDA support, export the environment variable <code>USE_CUDA=0</code>.
Other potentially useful environment variables may be found in <code>setup.py</code>.</p><p>If you are building for NVIDIA&rsquo;s Jetson platforms (Jetson Nano, TX1, TX2, AGX Xavier), Instructions to install PyTorch for Jetson Nano are <a href=https://devtalk.nvidia.com/default/topic/1049071/jetson-nano/pytorch-for-jetson-nano/ target=_blank>available here</a></p><div id=amd-rocm-support class=anchor></div><h5 class="relative group">AMD ROCm Support
<span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#amd-rocm-support aria-label=Anchor>#</a></span></h5><p>If you want to compile with ROCm support, install</p><ul><li><a href=https://rocm.docs.amd.com/en/latest/deploy/linux/quick_start.html target=_blank>AMD ROCm</a> 4.0 and above installation</li><li>ROCm is currently supported only for Linux systems.</li></ul><p>By default the build system expects ROCm to be installed in <code>/opt/rocm</code>. If ROCm is installed in a different directory, the <code>ROCM_PATH</code> environment variable must be set to the ROCm installation directory. The build system automatically detects the AMD GPU architecture. Optionally, the AMD GPU architecture can be explicitly set with the <code>PYTORCH_ROCM_ARCH</code> environment variable <a href=https://rocm.docs.amd.com/projects/install-on-linux/en/latest/reference/system-requirements.html#supported-gpus target=_blank>AMD GPU architecture</a></p><p>If you want to disable ROCm support, export the environment variable <code>USE_ROCM=0</code>.
Other potentially useful environment variables may be found in <code>setup.py</code>.</p><div id=intel-gpu-support class=anchor></div><h5 class="relative group">Intel GPU Support
<span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#intel-gpu-support aria-label=Anchor>#</a></span></h5><p>If you want to compile with Intel GPU support, follow these</p><ul><li><a href=https://www.intel.com/content/www/us/en/developer/articles/tool/pytorch-prerequisites-for-intel-gpus.html target=_blank>PyTorch Prerequisites for Intel GPUs</a> instructions.</li><li>Intel GPU is supported for Linux and Windows.</li></ul><p>If you want to disable Intel GPU support, export the environment variable <code>USE_XPU=0</code>.
Other potentially useful environment variables may be found in <code>setup.py</code>.</p><div id=get-the-pytorch-source class=anchor></div><h4 class="relative group">Get the PyTorch Source
<span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#get-the-pytorch-source aria-label=Anchor>#</a></span></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>git clone --recursive https://github.com/pytorch/pytorch
</span></span><span class=line><span class=cl><span class=nb>cd</span> pytorch
</span></span><span class=line><span class=cl><span class=c1># if you are updating an existing checkout</span>
</span></span><span class=line><span class=cl>git submodule sync
</span></span><span class=line><span class=cl>git submodule update --init --recursive
</span></span></code></pre></div><div id=install-dependencies class=anchor></div><h4 class="relative group">Install Dependencies
<span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#install-dependencies aria-label=Anchor>#</a></span></h4><p><strong>Common</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>conda install cmake ninja
</span></span><span class=line><span class=cl><span class=c1># Run this command on native Windows</span>
</span></span><span class=line><span class=cl>conda install rust
</span></span><span class=line><span class=cl><span class=c1># Run this command from the PyTorch directory after cloning the source code using the “Get the PyTorch Source“ section below</span>
</span></span><span class=line><span class=cl>pip install -r requirements.txt
</span></span></code></pre></div><p><strong>On Linux</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>pip install mkl-static mkl-include
</span></span><span class=line><span class=cl><span class=c1># CUDA only: Add LAPACK support for the GPU if needed</span>
</span></span><span class=line><span class=cl>conda install -c pytorch magma-cuda121  <span class=c1># or the magma-cuda* that matches your CUDA version from https://anaconda.org/pytorch/repo</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># (optional) If using torch.compile with inductor/triton, install the matching version of triton</span>
</span></span><span class=line><span class=cl><span class=c1># Run from the pytorch directory after cloning</span>
</span></span><span class=line><span class=cl><span class=c1># For Intel GPU support, please explicitly `export USE_XPU=1` before running command.</span>
</span></span><span class=line><span class=cl>make triton
</span></span></code></pre></div><p><strong>On MacOS</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Add this package on intel x86 processor machines only</span>
</span></span><span class=line><span class=cl>pip install mkl-static mkl-include
</span></span><span class=line><span class=cl><span class=c1># Add these packages if torch.distributed is needed</span>
</span></span><span class=line><span class=cl>conda install pkg-config libuv
</span></span></code></pre></div><p><strong>On Windows</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>pip install mkl-static mkl-include
</span></span><span class=line><span class=cl><span class=c1># Add these packages if torch.distributed is needed.</span>
</span></span><span class=line><span class=cl><span class=c1># Distributed package support on Windows is a prototype feature and is subject to changes.</span>
</span></span><span class=line><span class=cl>conda install -c conda-forge <span class=nv>libuv</span><span class=o>=</span>1.39
</span></span></code></pre></div><div id=install-pytorch class=anchor></div><h4 class="relative group">Install PyTorch
<span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#install-pytorch aria-label=Anchor>#</a></span></h4><p><strong>On Linux</strong></p><p>If you would like to compile PyTorch with <a href=https://gcc.gnu.org/onlinedocs/libstdc++/manual/using_dual_abi.html target=_blank>new C++ ABI</a> enabled, then first run this command:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nb>export</span> <span class=nv>_GLIBCXX_USE_CXX11_ABI</span><span class=o>=</span><span class=m>1</span>
</span></span></code></pre></div><p>Please <strong>note</strong> that starting from PyTorch 2.5, the PyTorch build with XPU supports both new and old C++ ABIs. Previously, XPU only supported the new C++ ABI. If you want to compile with Intel GPU support, please follow <a href=#intel-gpu-support>Intel GPU Support</a>.</p><p>If you&rsquo;re compiling for AMD ROCm then first run this command:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Only run this if you&#39;re compiling for ROCm</span>
</span></span><span class=line><span class=cl>python tools/amd_build/build_amd.py
</span></span></code></pre></div><p>Install PyTorch</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nb>export</span> <span class=nv>CMAKE_PREFIX_PATH</span><span class=o>=</span><span class=s2>&#34;</span><span class=si>${</span><span class=nv>CONDA_PREFIX</span><span class=k>:-</span><span class=s1>&#39;$(dirname $(which conda))/../&#39;</span><span class=si>}</span><span class=s2>:</span><span class=si>${</span><span class=nv>CMAKE_PREFIX_PATH</span><span class=si>}</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=cl>python setup.py develop
</span></span></code></pre></div><p><strong>On macOS</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>python3 setup.py develop
</span></span></code></pre></div><p><strong>On Windows</strong></p><p>If you want to build legacy python code, please refer to <a href=https://github.com/pytorch/pytorch/blob/main/CONTRIBUTING.md#building-on-legacy-code-and-cuda target=_blank>Building on legacy code and CUDA</a></p><p><strong>CPU-only builds</strong></p><p>In this mode PyTorch computations will run on your CPU, not your GPU</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-cmd data-lang=cmd><span class=line><span class=cl>python setup.py develop
</span></span></code></pre></div><p>Note on OpenMP: The desired OpenMP implementation is Intel OpenMP (iomp). In order to link against iomp, you&rsquo;ll need to manually download the library and set up the building environment by tweaking <code>CMAKE_INCLUDE_PATH</code> and <code>LIB</code>. The instruction <a href=https://github.com/pytorch/pytorch/blob/main/docs/source/notes/windows.rst#building-from-source target=_blank>here</a> is an example for setting up both MKL and Intel OpenMP. Without these configurations for CMake, Microsoft Visual C OpenMP runtime (vcomp) will be used.</p><p><strong>CUDA based build</strong></p><p>In this mode PyTorch computations will leverage your GPU via CUDA for faster number crunching</p><p><a href=https://docs.nvidia.com/gameworks/content/gameworkslibrary/nvtx/nvidia_tools_extension_library_nvtx.htm target=_blank>NVTX</a> is needed to build Pytorch with CUDA.
NVTX is a part of CUDA distributive, where it is called &ldquo;Nsight Compute&rdquo;. To install it onto an already installed CUDA run CUDA installation once again and check the corresponding checkbox.
Make sure that CUDA with Nsight Compute is installed after Visual Studio.</p><p>Currently, VS 2017 / 2019, and Ninja are supported as the generator of CMake. If <code>ninja.exe</code> is detected in <code>PATH</code>, then Ninja will be used as the default generator, otherwise, it will use VS 2017 / 2019.<br>If Ninja is selected as the generator, the latest MSVC will get selected as the underlying toolchain.</p><p>Additional libraries such as
<a href=https://developer.nvidia.com/magma target=_blank>Magma</a>, <a href=https://github.com/oneapi-src/oneDNN target=_blank>oneDNN, a.k.a. MKLDNN or DNNL</a>, and <a href=https://github.com/mozilla/sccache target=_blank>Sccache</a> are often needed. Please refer to the <a href=https://github.com/pytorch/pytorch/tree/main/.ci/pytorch/win-test-helpers/installation-helpers target=_blank>installation-helper</a> to install them.</p><p>You can refer to the <a href=https://github.com/pytorch/pytorch/blob/main/.ci/pytorch/win-test-helpers/build_pytorch.bat target=_blank>build_pytorch.bat</a> script for some other environment variables configurations</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-cmd data-lang=cmd><span class=line><span class=cl>cmd
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=p>:</span><span class=c1>: Set the environment variables after you have downloaded and unzipped the mkl package,</span>
</span></span><span class=line><span class=cl><span class=p>:</span><span class=c1>: else CMake would throw an error as `Could NOT find OpenMP`.</span>
</span></span><span class=line><span class=cl><span class=k>set</span> <span class=nv>CMAKE_INCLUDE_PATH</span><span class=p>=</span>{Your directory}\mkl\include
</span></span><span class=line><span class=cl><span class=k>set</span> <span class=nv>LIB</span><span class=p>=</span>{Your directory}\mkl\lib;<span class=nv>%LIB%</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=p>:</span><span class=c1>: Read the content in the previous section carefully before you proceed.</span>
</span></span><span class=line><span class=cl><span class=p>:</span><span class=c1>: [Optional] If you want to override the underlying toolset used by Ninja and Visual Studio with CUDA, please run the following script block.</span>
</span></span><span class=line><span class=cl><span class=p>:</span><span class=c1>: &#34;Visual Studio 2019 Developer Command Prompt&#34; will be run automatically.</span>
</span></span><span class=line><span class=cl><span class=p>:</span><span class=c1>: Make sure you have CMake &gt;= 3.12 before you do this when you use the Visual Studio generator.</span>
</span></span><span class=line><span class=cl><span class=k>set</span> <span class=nv>CMAKE_GENERATOR_TOOLSET_VERSION</span><span class=p>=</span>14.27
</span></span><span class=line><span class=cl><span class=k>set</span> <span class=nv>DISTUTILS_USE_SDK</span><span class=p>=</span>1
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=k>/f</span> <span class=s2>&#34;usebackq tokens=*&#34;</span> <span class=nv>%i in (`&#34;%</span>ProgramFiles(x86)<span class=nv>%\Microsoft Visual Studio\Installer\vswhere.exe&#34; -version [15^,17^) -products * -latest -property installationPath`) do call &#34;%</span>i\VC\Auxiliary\Build\vcvarsall.bat<span class=s2>&#34; x64 -vcvars_ver=</span><span class=nv>%CMAKE_GENERATOR_TOOLSET_VERSION%</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=p>:</span><span class=c1>: [Optional] If you want to override the CUDA host compiler</span>
</span></span><span class=line><span class=cl>set CUDAHOSTCXX=C:\Program Files (x86<span class=p>)</span>\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.27.29110\bin\HostX64\x64\cl.exe
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>python setup.py develop
</span></span></code></pre></div><div id=adjust-build-options-optional class=anchor></div><h5 class="relative group">Adjust Build Options (Optional)
<span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#adjust-build-options-optional aria-label=Anchor>#</a></span></h5><p>You can adjust the configuration of cmake variables optionally (without building first), by doing
the following. For example, adjusting the pre-detected directories for CuDNN or BLAS can be done
with such a step.</p><p>On Linux</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nb>export</span> <span class=nv>CMAKE_PREFIX_PATH</span><span class=o>=</span><span class=s2>&#34;</span><span class=si>${</span><span class=nv>CONDA_PREFIX</span><span class=k>:-</span><span class=s1>&#39;$(dirname $(which conda))/../&#39;</span><span class=si>}</span><span class=s2>:</span><span class=si>${</span><span class=nv>CMAKE_PREFIX_PATH</span><span class=si>}</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=cl>python setup.py build --cmake-only
</span></span><span class=line><span class=cl>ccmake build  <span class=c1># or cmake-gui build</span>
</span></span></code></pre></div><p>On macOS</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nb>export</span> <span class=nv>CMAKE_PREFIX_PATH</span><span class=o>=</span><span class=s2>&#34;</span><span class=si>${</span><span class=nv>CONDA_PREFIX</span><span class=k>:-</span><span class=s1>&#39;$(dirname $(which conda))/../&#39;</span><span class=si>}</span><span class=s2>:</span><span class=si>${</span><span class=nv>CMAKE_PREFIX_PATH</span><span class=si>}</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=cl><span class=nv>MACOSX_DEPLOYMENT_TARGET</span><span class=o>=</span>10.9 <span class=nv>CC</span><span class=o>=</span>clang <span class=nv>CXX</span><span class=o>=</span>clang++ python setup.py build --cmake-only
</span></span><span class=line><span class=cl>ccmake build  <span class=c1># or cmake-gui build</span>
</span></span></code></pre></div><div id=docker-image class=anchor></div><h3 class="relative group">Docker Image
<span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#docker-image aria-label=Anchor>#</a></span></h3><div id=using-pre-built-images class=anchor></div><h4 class="relative group">Using pre-built images
<span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#using-pre-built-images aria-label=Anchor>#</a></span></h4><p>You can also pull a pre-built docker image from Docker Hub and run with docker v19.03+</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>docker run --gpus all --rm -ti --ipc<span class=o>=</span>host pytorch/pytorch:latest
</span></span></code></pre></div><p>Please note that PyTorch uses shared memory to share data between processes, so if torch multiprocessing is used (e.g.
for multithreaded data loaders) the default shared memory segment size that container runs with is not enough, and you
should increase shared memory size either with <code>--ipc=host</code> or <code>--shm-size</code> command line options to <code>nvidia-docker run</code>.</p><div id=building-the-image-yourself class=anchor></div><h4 class="relative group">Building the image yourself
<span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#building-the-image-yourself aria-label=Anchor>#</a></span></h4><p><strong>NOTE:</strong> Must be built with a docker version > 18.06</p><p>The <code>Dockerfile</code> is supplied to build images with CUDA 11.1 support and cuDNN v8.
You can pass <code>PYTHON_VERSION=x.y</code> make variable to specify which Python version is to be used by Miniconda, or leave it
unset to use the default.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>make -f docker.Makefile
</span></span><span class=line><span class=cl><span class=c1># images are tagged as docker.io/${your_docker_username}/pytorch</span>
</span></span></code></pre></div><p>You can also pass the <code>CMAKE_VARS="..."</code> environment variable to specify additional CMake variables to be passed to CMake during the build.
See <a href=./setup.py>setup.py</a> for the list of available variables.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>make -f docker.Makefile
</span></span></code></pre></div><div id=building-the-documentation class=anchor></div><h3 class="relative group">Building the Documentation
<span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#building-the-documentation aria-label=Anchor>#</a></span></h3><p>To build documentation in various formats, you will need <a href=http://www.sphinx-doc.org target=_blank>Sphinx</a> and the
readthedocs theme.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nb>cd</span> docs/
</span></span><span class=line><span class=cl>pip install -r requirements.txt
</span></span><span class=line><span class=cl>make html
</span></span><span class=line><span class=cl>make serve
</span></span></code></pre></div><p>Run <code>make</code> to get a list of all available output formats.</p><p>If you get a katex error run <code>npm install katex</code>. If it persists, try
<code>npm install -g katex</code></p><blockquote><p>Note: if you installed <code>nodejs</code> with a different package manager (e.g.,
<code>conda</code>) then <code>npm</code> will probably install a version of <code>katex</code> that is not
compatible with your version of <code>nodejs</code> and doc builds will fail.
A combination of versions that is known to work is <code>node@6.13.1</code> and
<code>katex@0.13.18</code>. To install the latter with <code>npm</code> you can run
<code>npm install -g katex@0.13.18</code></p></blockquote><div id=previous-versions class=anchor></div><h3 class="relative group">Previous Versions
<span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#previous-versions aria-label=Anchor>#</a></span></h3><p>Installation instructions and binaries for previous PyTorch versions may be found
on <a href=https://pytorch.org/previous-versions target=_blank>our website</a>.</p><div id=getting-started class=anchor></div><h2 class="relative group">Getting Started
<span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#getting-started aria-label=Anchor>#</a></span></h2><p>Three-pointers to get you started:</p><ul><li><a href=https://pytorch.org/tutorials/ target=_blank>Tutorials: get you started with understanding and using PyTorch</a></li><li><a href=https://github.com/pytorch/examples target=_blank>Examples: easy to understand PyTorch code across all domains</a></li><li><a href=https://pytorch.org/docs/ target=_blank>The API Reference</a></li><li><a href=https://github.com/pytorch/pytorch/blob/main/GLOSSARY.md target=_blank>Glossary</a></li></ul><div id=resources class=anchor></div><h2 class="relative group">Resources
<span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#resources aria-label=Anchor>#</a></span></h2><ul><li><a href=https://pytorch.org/ target=_blank>PyTorch.org</a></li><li><a href=https://pytorch.org/tutorials/ target=_blank>PyTorch Tutorials</a></li><li><a href=https://github.com/pytorch/examples target=_blank>PyTorch Examples</a></li><li><a href=https://pytorch.org/hub/ target=_blank>PyTorch Models</a></li><li><a href=https://www.udacity.com/course/deep-learning-pytorch--ud188 target=_blank>Intro to Deep Learning with PyTorch from Udacity</a></li><li><a href=https://www.udacity.com/course/intro-to-machine-learning-nanodegree--nd229 target=_blank>Intro to Machine Learning with PyTorch from Udacity</a></li><li><a href=https://www.coursera.org/learn/deep-neural-networks-with-pytorch target=_blank>Deep Neural Networks with PyTorch from Coursera</a></li><li><a href=https://twitter.com/PyTorch target=_blank>PyTorch Twitter</a></li><li><a href=https://pytorch.org/blog/ target=_blank>PyTorch Blog</a></li><li><a href=https://www.youtube.com/channel/UCWXI5YeOsh03QvJ59PMaXFw target=_blank>PyTorch YouTube</a></li></ul><div id=communication class=anchor></div><h2 class="relative group">Communication
<span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#communication aria-label=Anchor>#</a></span></h2><ul><li>Forums: Discuss implementations, research, etc. <a href=https://discuss.pytorch.org target=_blank>https://discuss.pytorch.org</a></li><li>GitHub Issues: Bug reports, feature requests, install issues, RFCs, thoughts, etc.</li><li>Slack: The <a href=https://pytorch.slack.com/ target=_blank>PyTorch Slack</a> hosts a primary audience of moderate to experienced PyTorch users and developers for general chat, online discussions, collaboration, etc. If you are a beginner looking for help, the primary medium is <a href=https://discuss.pytorch.org target=_blank>PyTorch Forums</a>. If you need a slack invite, please fill this form: <a href=https://goo.gl/forms/PP1AGvNHpSaJP8to1 target=_blank>https://goo.gl/forms/PP1AGvNHpSaJP8to1</a></li><li>Newsletter: No-noise, a one-way email newsletter with important announcements about PyTorch. You can sign-up here: <a href=https://eepurl.com/cbG0rv target=_blank>https://eepurl.com/cbG0rv</a></li><li>Facebook Page: Important announcements about PyTorch. <a href=https://www.facebook.com/pytorch target=_blank>https://www.facebook.com/pytorch</a></li><li>For brand guidelines, please visit our website at <a href=https://pytorch.org/ target=_blank>pytorch.org</a></li></ul><div id=releases-and-contributing class=anchor></div><h2 class="relative group">Releases and Contributing
<span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#releases-and-contributing aria-label=Anchor>#</a></span></h2><p>Typically, PyTorch has three minor releases a year. Please let us know if you encounter a bug by <a href=https://github.com/pytorch/pytorch/issues target=_blank>filing an issue</a>.</p><p>We appreciate all contributions. If you are planning to contribute back bug-fixes, please do so without any further discussion.</p><p>If you plan to contribute new features, utility functions, or extensions to the core, please first open an issue and discuss the feature with us.
Sending a PR without discussion might end up resulting in a rejected PR because we might be taking the core in a different direction than you might be aware of.</p><p>To learn more about making a contribution to Pytorch, please see our <a href=CONTRIBUTING.md>Contribution page</a>. For more information about PyTorch releases, see <a href=RELEASE.md>Release page</a>.</p><div id=the-team class=anchor></div><h2 class="relative group">The Team
<span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#the-team aria-label=Anchor>#</a></span></h2><p>PyTorch is a community-driven project with several skillful engineers and researchers contributing to it.</p><p>PyTorch is currently maintained by <a href=http://soumith.ch target=_blank>Soumith Chintala</a>, <a href=https://github.com/gchanan target=_blank>Gregory Chanan</a>, <a href=https://github.com/dzhulgakov target=_blank>Dmytro Dzhulgakov</a>, <a href=https://github.com/ezyang target=_blank>Edward Yang</a>, and <a href=https://github.com/malfet target=_blank>Nikita Shulga</a> with major contributions coming from hundreds of talented individuals in various forms and means.
A non-exhaustive but growing list needs to mention: <a href=https://github.com/killeent target=_blank>Trevor Killeen</a>, <a href=https://github.com/chsasank target=_blank>Sasank Chilamkurthy</a>, <a href=https://github.com/szagoruyko target=_blank>Sergey Zagoruyko</a>, <a href=https://github.com/adamlerer target=_blank>Adam Lerer</a>, <a href=https://github.com/fmassa target=_blank>Francisco Massa</a>, <a href=https://github.com/alykhantejani target=_blank>Alykhan Tejani</a>, <a href=https://github.com/lantiga target=_blank>Luca Antiga</a>, <a href=https://github.com/albanD target=_blank>Alban Desmaison</a>, <a href=https://github.com/andreaskoepf target=_blank>Andreas Koepf</a>, <a href=https://github.com/jamesb93 target=_blank>James Bradbury</a>, <a href=https://github.com/ebetica target=_blank>Zeming Lin</a>, <a href=https://github.com/yuandong-tian target=_blank>Yuandong Tian</a>, <a href=https://github.com/glample target=_blank>Guillaume Lample</a>, <a href=https://github.com/Maratyszcza target=_blank>Marat Dukhan</a>, <a href=https://github.com/ngimel target=_blank>Natalia Gimelshein</a>, <a href=https://github.com/csarofeen target=_blank>Christian Sarofeen</a>, <a href=https://github.com/martinraison target=_blank>Martin Raison</a>, <a href=https://github.com/ezyang target=_blank>Edward Yang</a>, <a href=https://github.com/zdevito target=_blank>Zachary Devito</a>.</p><p>Note: This project is unrelated to <a href=https://github.com/hughperkins/pytorch target=_blank>hughperkins/pytorch</a> with the same name. Hugh is a valuable contributor to the Torch community and has helped with many things Torch and PyTorch.</p><div id=license class=anchor></div><h2 class="relative group">License
<span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#license aria-label=Anchor>#</a></span></h2><p>PyTorch has a BSD-style license, as found in the <a href=LICENSE>LICENSE</a> file.</p></div></div><script>var oid="views_projects/pytorch.md",oid_likes="likes_projects/pytorch.md"</script><script type=text/javascript src=/js/page.min.0e49973b4ad0a382c7c6012d8bff8226316642daabc4f8a20477bd08674f3da6e2fa993bc20ad4f51e7c5bb68e6f913a207a7c4fe37ea0e7b806894afce0a64e.js integrity="sha512-DkmXO0rQo4LHxgEti/+CJjFmQtqrxPiiBHe9CGdPPabi+pk7wgrU9R58W7aOb5E6IHp8T+N+oOe4BolK/OCmTg=="></script></section><footer class="pt-8 max-w-prose print:hidden"><div class=pt-8><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class="flex justify-between pt-3"><span><a class="flex group mr-3" href=/projects/special-relativity-time-dilation/><span class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400">&larr;</span>
<span class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400">&rarr;</span>
<span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">special-relativity-time-dilation</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime="2024-08-27 00:00:00 +0000 UTC">27 August 2024</time></span></span></a></span>
<span><a class="flex text-right group ml-3" href=/projects/component/><span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">component</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime="2024-09-04 00:00:00 +0000 UTC">4 September 2024</time></span></span>
<span class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400">&rarr;</span>
<span class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400">&larr;</span></a></span></div></div></footer></article><div id=top-scroller class="pointer-events-none absolute top-[110vh] bottom-0 w-12 ltr:right-0 rtl:left-0"><a href=#the-top class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 mb-16 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 backdrop-blur hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400" aria-label="Scroll to top" title="Scroll to top">&uarr;</a></div></main><footer id=site-footer class="py-10 print:hidden"><div class="flex items-center justify-between"><p class="text-sm text-neutral-500 dark:text-neutral-400">&copy;
2025
Jake Roggenbuck</p></div><script>mediumZoom(document.querySelectorAll("img:not(.nozoom)"),{margin:24,background:"rgba(0,0,0,0.5)",scrollOffset:0})</script><script type=text/javascript src=/js/process.min.35c1113bcc16c5a59bf031082f9e63822aa95280423881a7847a7ff33a16e6299ce6a840d9ef4e10d947e030a18f3f20359afb2ec0f35967484b9a9360ac3145.js integrity="sha512-NcERO8wWxaWb8DEIL55jgiqpUoBCOIGnhHp/8zoW5imc5qhA2e9OENlH4DChjz8gNZr7LsDzWWdIS5qTYKwxRQ=="></script></footer><div id=search-wrapper class="invisible fixed inset-0 flex h-screen w-screen cursor-default flex-col bg-neutral-500/50 p-4 backdrop-blur-sm dark:bg-neutral-900/50 sm:p-6 md:p-[10vh] lg:p-[12vh]" data-url style=z-index:500><div id=search-modal class="flex flex-col w-full max-w-3xl min-h-0 mx-auto border rounded-md shadow-lg top-20 border-neutral-200 bg-neutral dark:border-neutral-700 dark:bg-neutral-800"><header class="relative z-10 flex items-center justify-between flex-none px-2"><form class="flex items-center flex-auto min-w-0"><div class="flex items-center justify-center w-8 h-8 text-neutral-400"><span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></div><input type=search id=search-query class="flex flex-auto h-12 mx-1 bg-transparent appearance-none focus:outline-dotted focus:outline-2 focus:outline-transparent" placeholder=Search tabindex=0></form><button id=close-search-button class="flex items-center justify-center w-8 h-8 text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400" title="Close (Esc)">
<span class="relative block icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></button></header><section class="flex-auto px-2 overflow-auto"><ul id=search-results></ul></section></div></div></div></body></html>