<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><style>:root{--accent-color:#FF4D4D}</style><title>gpt-2</title><meta name=description content="Software Developer & Student"><meta name=keywords content><meta property="og:url" content="https://jr0.org/projects/gpt-2/"><meta property="og:type" content="website"><meta property="og:title" content="gpt-2"><meta property="og:description" content="Software Developer & Student"><meta property="og:image" content="/images/35516367.jpg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:title content="gpt-2"><meta name=twitter:description content="Software Developer & Student"><meta property="twitter:domain" content="https://jr0.org/projects/gpt-2/"><meta property="twitter:url" content="https://jr0.org/projects/gpt-2/"><meta name=twitter:image content="/images/35516367.jpg"><link rel=canonical href=https://jr0.org/projects/gpt-2/><link rel=stylesheet type=text/css href=https://jr0.org/css/normalize.min.css media=print onload='this.media="all"'><link rel=stylesheet type=text/css href=https://jr0.org/css/main.css><link disabled id=dark-theme rel=stylesheet href=https://jr0.org/css/dark.css><script src=https://jr0.org/js/svg-injector.min.js></script>
<script src=https://jr0.org/js/feather-icons.min.js></script>
<script src=https://jr0.org/js/main.js></script>
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.css integrity=sha384-Xi8rHCmBmhbuyyhbI88391ZKP2dmfnOl4rT9ZfRI7mLTdk1wblIUnrIq35nqwEvC crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.js integrity=sha384-X/XCfMm41VSsqRNQgDerQczD69XqmjOOOwYQvr/uuC+j4OPoNhVgjdGFwhvN02Ja crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous></script>
<script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],throwOnError:!1})})</script><script>!function(e,t){var n,s,o,i;t.__SV||(window.posthog=t,t._i=[],t.init=function(a,r,c){function d(e,t){var n=t.split(".");2==n.length&&(e=e[n[0]],t=n[1]),e[t]=function(){e.push([t].concat(Array.prototype.slice.call(arguments,0)))}}(s=e.createElement("script")).type="text/javascript",s.async=!0,s.src=r.api_host+"/static/array.js",(i=e.getElementsByTagName("script")[0]).parentNode.insertBefore(s,i);var l=t;for(void 0!==c?l=t[c]=[]:c="posthog",l.people=l.people||[],l.toString=function(e){var t="posthog";return"posthog"!==c&&(t+="."+c),e||(t+=" (stub)"),t},l.people.toString=function(){return l.toString(1)+".people (stub)"},o="capture identify alias people.set people.set_once set_config register register_once unregister opt_out_capturing has_opted_out_capturing opt_in_capturing reset isFeatureEnabled onFeatureFlags".split(" "),n=0;n<o.length;n++)d(l,o[n]);t._i.push([a,r,c])},t.__SV=1)}(document,window.posthog||[]),posthog.init("phc_ML7OV6jGM1EXu0tXlV5CUqJgBSduSsgx8U2HaLEiIX",{api_host:"https://app.posthog.com"})</script></head><body><script type=text/javascript>setThemeByUserPref()</script><header class=header><nav class=header-nav><div class=avatar><a href=https://jr0.org><img src=https://jr0.org/images/35516367.jpg alt=avatar></a></div><div class=nav-title><a class=nav-brand href=https://jr0.org>JR0.org</a></div><div class=nav-links><div class=nav-link><a href=https://jr0.org/><span data-feather=home></span> Home</a></div><div class=nav-link><a href=https://jr0.org/projects/><span data-feather=code></span> Projects</a></div><div class=nav-link><a href=https://jr0.org/research/><span data-feather=book></span> Research</a></div><div class=nav-link><a href=https://jr0.org/devlogs/><span data-feather=book></span> Devlog</a></div><div class=nav-link><a href=https://jr0.org/posts/><span data-feather=book></span> Posts</a></div><div class=nav-link><a href=https://jr0.org/tags/><span data-feather=tag></span> Tags</a></div><div class=nav-link><a href=https://github.com/jakeroggenbuck/JakeRoggenbuck.github.io><span data-feather=github></span></a></div><span class=nav-icons-divider></span><div class="nav-link dark-theme-toggle"><span id=dark-theme-toggle-screen-reader-target class=sr-only></span>
<a><span id=theme-toggle-icon data-feather=moon></span></a></div><div class=nav-link id=hamburger-menu-toggle><span id=hamburger-menu-toggle-screen-reader-target class=sr-only>menu</span>
<a><span data-feather=menu></span></a></div><ul class="nav-hamburger-list visibility-hidden"><li class=nav-item><a href=https://jr0.org/><span data-feather=home></span> Home</a></li><li class=nav-item><a href=https://jr0.org/projects/><span data-feather=code></span> Projects</a></li><li class=nav-item><a href=https://jr0.org/research/><span data-feather=book></span> Research</a></li><li class=nav-item><a href=https://jr0.org/devlogs/><span data-feather=book></span> Devlog</a></li><li class=nav-item><a href=https://jr0.org/posts/><span data-feather=book></span> Posts</a></li><li class=nav-item><a href=https://jr0.org/tags/><span data-feather=tag></span> Tags</a></li><li class=nav-item><a href=https://github.com/jakeroggenbuck/JakeRoggenbuck.github.io><span data-feather=github></span></a></li><li class="nav-item dark-theme-toggle"><span id=dark-theme-toggle-screen-reader-target class=sr-only>theme</span>
<a><span id=theme-toggle-icon data-feather=moon></span></a></li></ul></div></nav></header><main id=content><div class="post container"><div class=post-header-section><h1>gpt-2</h1></div><div class=post-content><p><p><a href=https://github.com/jakeroggenbuck/gpt-2/>See on GitHub</a></p><h1 id=gpt-2>gpt-2</h1><p>Code from the paper <a href=https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf>&ldquo;Language Models are Unsupervised Multitask Learners&rdquo;</a>.</p><p>We have currently released small (117M parameter) and medium (345M parameter) versions of GPT-2. While we have not released the larger models, we have <a href=https://github.com/openai/gpt-2-output-dataset>released a dataset</a> for researchers to study their behaviors.</p><p>See more details in our <a href=https://blog.openai.com/better-language-models/>blog post</a>.</p><h2 id=usage>Usage</h2><p>This repository is meant to be a starting point for researchers and engineers to experiment with GPT-2.</p><h3 id=some-caveats>Some caveats</h3><ul><li>GPT-2 models&rsquo; robustness and worst case behaviors are not well-understood. As with any machine-learned model, carefully evaluate GPT-2 for your use case, especially if used without fine-tuning or in safety-critical applications where reliability is important.</li><li>The dataset our GPT-2 models were trained on contains many texts with <a href=https://twitter.com/TomerUllman/status/1101485289720242177>biases</a> and factual inaccuracies, and thus GPT-2 models are likely to be biased and inaccurate as well.</li><li>To avoid having samples mistaken as human-written, we recommend clearly labeling samples as synthetic before wide dissemination. Our models are often incoherent or inaccurate in subtle ways, which takes more than a quick read for a human to notice.</li></ul><h3 id=work-with-us>Work with us</h3><p>Please <a href=mailto:languagequestions@openai.com>let us know</a> if you’re doing interesting research with or working on applications of GPT-2! We’re especially interested in hearing from and potentially working with those who are studying</p><ul><li>Potential malicious use cases and defenses against them (e.g. the detectability of synthetic text)</li><li>The extent of problematic content (e.g. bias) being baked into the models and effective mitigations</li></ul><h2 id=development>Development</h2><p>See <a href=./DEVELOPERS.md>DEVELOPERS.md</a></p><h2 id=contributors>Contributors</h2><p>See <a href=./CONTRIBUTORS.md>CONTRIBUTORS.md</a></p><h2 id=citation>Citation</h2><p>Please use the following bibtex entry:</p><pre tabindex=0><code>@article{radford2019language,
  title={Language Models are Unsupervised Multitask Learners},
  author={Radford, Alec and Wu, Jeff and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  year={2019}
}
</code></pre><h2 id=future-work>Future work</h2><p>We may release code for evaluating the models on various benchmarks.</p><p>We are still considering release of the larger models.</p><h2 id=license>License</h2><p><a href=./LICENSE>MIT</a></p></p></div></div></main><footer class=footer><span>&copy; 2023 Jake Roggenbuck</span>
<span>Made with &#10084;&#65039; using <a target=_blank href=https://github.com/526avijitgupta/gokarna>Gokarna</a></span></footer></body></html>